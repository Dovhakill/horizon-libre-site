name: AutoTweet on New Article

on:
  push:
    paths:
      - 'article/*.html'
  repository_dispatch:
    types: [new-article-published]

jobs:
  tweet:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Overwrite autotweet.py
        shell: bash
        run: |
          cat << 'EOF' > autotweet.py
          import os
          import sys
          import json
          import hashlib
          import time
          import requests
          import tweepy
          from bs4 import BeautifulSoup
          from PIL import Image
          from io import BytesIO
          try:
              import google.generativeai as genai
          except ImportError:
              genai = None

          # Constants
          SITE_URL = "https://horizon-libre.net"
          ARTICLES_DIR = "article"
          MAX_TWEET_LENGTH = 280
          UTM_PARAMS = "?utm_source=twitter&utm_medium=social&utm_campaign=autotweet"
          GEMINI_MODEL_DEFAULT = "gemini-1.5-flash"
          PAUSE_BETWEEN_TWEETS = 2  # seconds

          # Logging function
          def log(message):
              print(message, flush=True)

          # Memory functions for deduplication
          def get_memory_key(article_path):
              return hashlib.sha256(article_path.encode()).hexdigest().lower()

          def has_been_seen(key, blobs_url, token):
              if not blobs_url or not token:
                  return False
              try:
                  url = f"{blobs_url}/{key}"
                  response = requests.get(url, headers={"X-AURORE-TOKEN": token})
                  return response.status_code == 200
              except Exception as e:
                  log(f"Memory check failed: {e}")
                  return False

          def mark_as_seen(key, blobs_url, token):
              if not blobs_url or not token:
                  return
              try:
                  url = f"{blobs_url}/{key}"
                  requests.put(url, data="1", headers={"X-AURORE-TOKEN": token})
              except Exception as e:
                  log(f"Memory mark failed: {e}")

          # Read GitHub event
          def read_github_event():
              event_path = os.environ.get("GITHUB_EVENT_PATH")
              if event_path:
                  with open(event_path, "r") as f:
                      return json.load(f)
              return None

          # Detect new articles (with debug logs)
          def detect_new_articles():
              event = read_github_event()
              if event:
                  log(f"Event keys: {list(event.keys())}")
                  if event.get("action") == "new-article-published":
                      payload = event.get("client_payload", {})
                      articles = payload.get("articles", [])
                      log(f"Repository dispatch articles: {articles}")
                      return articles
                  elif "commits" in event:
                      log(f"Number of commits: {len(event['commits'])}")
                      added_files = set()
                      for commit in event.get("commits", []):
                          added = commit.get("added", [])
                          log(f"Added files in commit {commit.get('id')}: {added}")
                          for file in added:
                              if file.startswith(ARTICLES_DIR + "/") and file.endswith(".html"):
                                  added_files.add(file)
                      return list(added_files)
              else:
                  log("No GitHub event found")
              return []

          # Parse HTML for title and category
          def parse_article(article_path):
              try:
                  with open(article_path, "r", encoding="utf-8") as f:
                      soup = BeautifulSoup(f.read(), "html.parser")
                  title = soup.title.string.strip() if soup.title else "Untitled"
                  category = None
                  meta_section = soup.find("meta", {"property": "article:section"})
                  if meta_section:
                      category = meta_section["content"].strip()
                  else:
                      meta_category = soup.find("meta", {"name": "category"})
                      if meta_category:
                          category = meta_category["content"].strip()
                  return title, category
              except Exception as e:
                  log(f"Parsing failed for {article_path}: {e}")
                  return None, None

          # Generate hashtags
          def generate_hashtags(title, category):
              hashtags = ["#HorizonLibre"]
              if category:
                  hashtags.append(f"#{category.replace(' ', '').lower()}")
              elif title:
                  # Simple keyword from title as fallback
                  words = title.split()
                  if words:
                      hashtags.append(f"#{words[0].lower()}")
              return " ".join(set(hashtags[:2]))  # At most 2 unique

          # Append UTM if enabled
          def append_utm(url):
              if os.environ.get("ENABLE_UTM"):
                  return url + UTM_PARAMS
              return url

          # Safe trim to max length
          def safe_trim(text, max_len=MAX_TWEET_LENGTH):
              if len(text) <= max_len:
                  return text
              return text[:max_len - 3] + "..."

          # Generate alt text
          def generate_alt_text(image_data, gemini_api_key, gemini_model):
              if gemini_api_key and genai:
                  try:
                      genai.configure(api_key=gemini_api_key)
                      model = genai.GenerativeModel(gemini_model)
                      response = model.generate_content(["Describe this image briefly for accessibility.", image_data])
                      alt = response.text.strip()[:1000]
                      return alt if alt else "Image from article"
                  except Exception as e:
                      log(f"Gemini failed: {e}")
              # Fallback local: simple placeholder
              return "Image from article"

          # Find and prepare image
          def find_and_prepare_image(article_path, soup):
              try:
                  # Find image URL
                  img_url = None
                  og_image = soup.find("meta", {"property": "og:image"})
                  if og_image:
                      img_url = og_image["content"]
                  else:
                      twitter_image = soup.find("meta", {"name": "twitter:image"})
                      if twitter_image:
                          img_url = twitter_image["content"]
                      else:
                          image_src = soup.find("link", {"rel": "image_src"})
                          if image_src:
                              img_url = image_src["href"]
                          else:
                              article_tag = soup.find("article")
                              if article_tag:
                                  img_tag = article_tag.find("img")
                                  if img_tag:
                                      img_url = img_tag["src"]
                                      # Fallback alt from HTML
                                      alt = img_tag.get("alt") or img_tag.find_parent("figure").find("figcaption").text.strip() if img_tag.find_parent("figure") else None
                  if not img_url:
                      return None, None

                  # Resolve path
                  if not img_url.startswith("http"):
                      img_url = os.path.join(os.path.dirname(article_path), img_url)
                      with open(img_url, "rb") as f:
                          img_data = f.read()
                  else:
                      response = requests.get(img_url)
                      img_data = response.content

                  # Prepare image: RGB, max 4096px, JPEG progressive <=4.8MB
                  img = Image.open(BytesIO(img_data))
                  img = img.convert("RGB")
                  max_size = 4096
                  if img.width > max_size or img.height > max_size:
                      ratio = min(max_size / img.width, max_size / img.height)
                      img = img.resize((int(img.width * ratio), int(img.height * ratio)), Image.LANCZOS)
                  quality = 95
                  while True:
                      buffer = BytesIO()
                      img.save(buffer, format="JPEG", progressive=True, quality=quality)
                      size = buffer.tell()
                      if size <= 4.8 * 1024 * 1024 or quality <= 50:
                          break
                      quality -= 5
                  return buffer.getvalue(), alt
              except Exception as e:
                  log(f"Image processing failed: {e}")
                  return None, None

          # Build tweet text
          def build_tweet_text(title, hashtags, article_url):
              base = f"Nouvel article: {title}"
              tweet = f"{base} {hashtags} {article_url}"
              return safe_trim(tweet)

          # Post tweet
          def post_tweet(tweet_text, image_data=None, alt_text=None):
              try:
                  consumer_key = os.environ["X_API_KEY"]
                  consumer_secret = os.environ["X_API_SECRET"]
                  access_token = os.environ["X_ACCESS_TOKEN"]
                  access_token_secret = os.environ["X_ACCESS_TOKEN_SECRET"]
                  auth = tweepy.OAuth1UserHandler(consumer_key, consumer_secret, access_token, access_token_secret)
                  api = tweepy.API(auth)
                  if image_data:
                      media = api.media_upload(filename="image.jpg", file=BytesIO(image_data))
                      api.update_status(status=tweet_text, media_ids=[media.media_id], possibly_sensitive=False, attachment_url=None)
                      if alt_text:
                          api.create_media_metadata(media.media_id, alt_text)
                  else:
                      api.update_status(status=tweet_text)
                  log("Tweet posted successfully")
              except Exception as e:
                  log(f"Tweet posting failed: {e}")

          # Main function
          def main():
              articles = detect_new_articles()
              log(f"Detected articles: {articles}")
              if not articles:
                  log("No new articles found")
                  return

              blobs_url = os.environ.get("BLOBS_PROXY_URL")
              aurore_token = os.environ.get("AURORE_BLOBS_TOKEN")
              gemini_api_key = os.environ.get("GEMINI_API_KEY_HORIZON")
              gemini_model = os.environ.get("GEMINI_MODEL", GEMINI_MODEL_DEFAULT)

              for idx, article_path in enumerate(articles):
                  key = get_memory_key(article_path)
                  if has_been_seen(key, blobs_url, aurore_token):
                      log(f"Skipping duplicate: {article_path}")
                      continue

                  title, category = parse_article(article_path)
                  if not title:
                      log(f"Skipping invalid article: {article_path}")
                      continue

                  with open(article_path, "r", encoding="utf-8") as f:
                      soup = BeautifulSoup(f.read(), "html.parser")

                  hashtags = generate_hashtags(title, category)
                  article_url = append_utm(f"{SITE_URL}/{article_path}")
                  tweet_text = build_tweet_text(title, hashtags, article_url)

                  image_data, html_alt = find_and_prepare_image(article_path, soup)
                  alt_text = html_alt if html_alt else generate_alt_text(image_data, gemini_api_key, gemini_model) if image_data else None

                  post_tweet(tweet_text, image_data, alt_text)

                  mark_as_seen(key, blobs_url, aurore_token)

                  if idx < len(articles) - 1:
                      time.sleep(PAUSE_BETWEEN_TWEETS)

          if __name__ == "__main__":
              main()
          EOF
      - name: Display first 40 lines of autotweet.py
        run: head -n 40 autotweet.py
      - name: Compile check autotweet.py
        run: python -m py_compile autotweet.py
      - name: Install dependencies
        run: pip install -r requirements-autotweet.txt
      - name: Run autotweet
        run: python autotweet.py
        env:
          X_API_KEY: ${{ secrets.X_API_KEY }}
          X_API_SECRET: ${{ secrets.X_API_SECRET }}
          X_ACCESS_TOKEN: ${{ secrets.X_ACCESS_TOKEN }}
          X_ACCESS_TOKEN_SECRET: ${{ secrets.X_ACCESS_TOKEN_SECRET }}
          GEMINI_API_KEY_HORIZON: ${{ secrets.GEMINI_API_KEY_HORIZON }}
          GEMINI_MODEL: ${{ secrets.GEMINI_MODEL }}
          BLOBS_PROXY_URL: ${{ secrets.BLOBS_PROXY_URL }}
          AURORE_BLOBS_TOKEN: ${{ secrets.AURORE_BLOBS_TOKEN }}
          ENABLE_UTM: ${{ secrets.ENABLE_UTM }}
